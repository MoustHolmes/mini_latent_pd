{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_latent_pd.models.minifold.model.model import MiniFoldModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ef075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b97539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from mini_latent_pd.models.minifold.model.model import MiniFoldModel\n",
    "from mini_latent_pd.models.minifold.data.config import model_config\n",
    "from mini_latent_pd.models.minifold.data.of_data import of_inference\n",
    "from mini_latent_pd.models.minifold.utils.residue_constants import restype_order_with_x_inverse\n",
    "from esm.pretrained import load_model_and_alphabet\n",
    "\n",
    "def load_minifold_model(cache_dir=\"./minifold_cache\", model_size=\"48L\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Loads the MiniFold model, alphabet, and config for interactive use.\n",
    "    \"\"\"\n",
    "    # 1. Paths\n",
    "    cache = Path(cache_dir).expanduser()\n",
    "    checkpoint_path = cache / f\"minifold_{model_size}.ckpt\"\n",
    "    \n",
    "    if not checkpoint_path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}. Run predict.py once to download it.\")\n",
    "\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "    \n",
    "    # 2. Load Checkpoint & Hyperparams\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    hparams = ckpt[\"hyper_parameters\"]\n",
    "    \n",
    "    # 3. Initialize Model\n",
    "    # We create the config required for feature generation\n",
    "    config_of = model_config(\n",
    "        \"initial_training\",\n",
    "        train=False,\n",
    "        low_prec=False,\n",
    "        long_sequence_inference=False,\n",
    "    )\n",
    "    \n",
    "    model = MiniFoldModel(\n",
    "        esm_model_name=hparams[\"esm_model_name\"],\n",
    "        num_blocks=hparams[\"num_blocks\"],\n",
    "        no_bins=hparams[\"no_bins\"],\n",
    "        config_of=config_of,\n",
    "        use_structure_module=True,\n",
    "        kernels=False, # Important: False for Mac/MPS compatibility\n",
    "    )\n",
    "\n",
    "    # 4. Load State Dict\n",
    "    state_dict = ckpt[\"state_dict\"]\n",
    "    # Clean keys as done in predict.py\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"boundaries\" not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"mid_points\" not in k}\n",
    "    state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "    state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 5. Load Alphabet (needed for tokenizing sequences)\n",
    "    _, alphabet = load_model_and_alphabet(hparams[\"esm_model_name\"])\n",
    "    \n",
    "    return model, alphabet, config_of.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9199a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinifoldCollator:\n",
    "    def __init__(self, alphabet, config):\n",
    "        self.alphabet = alphabet\n",
    "        self.config = config\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        Transforms a list of mdCATH dicts into a MiniFold batch.\n",
    "        \"\"\"\n",
    "        seq_tokens_list = []\n",
    "        masks_list = []\n",
    "        batch_of_list = []\n",
    "        gt_coords_list = []\n",
    "        ids = []\n",
    "\n",
    "        for item in batch:\n",
    "            seq_str = item[\"sequence\"]\n",
    "            ids.append(item[\"id\"])\n",
    "            \n",
    "            # --- A. Generate Features ---\n",
    "            # This replicates predict.py's `prepare_input`\n",
    "            of_feats = of_inference(seq_str, \"predict\", self.config)\n",
    "            \n",
    "            # Reconstruct clean sequence from features to ensure alignment\n",
    "            clean_seq = \"\".join(\n",
    "                [restype_order_with_x_inverse[x.item()] for x in of_feats[\"aatype\"]]\n",
    "            )[: of_feats[\"seq_length\"]]\n",
    "            \n",
    "            # Encode for ESM\n",
    "            encoded_seq = torch.tensor(self.alphabet.encode(clean_seq), dtype=torch.long)\n",
    "            \n",
    "            # --- B. Collect ---\n",
    "            seq_tokens_list.append(encoded_seq)\n",
    "            masks_list.append(of_feats[\"seq_mask\"][:, 0].bool())\n",
    "            \n",
    "            # Filter OpenFold features to only what MiniFold needs\n",
    "            relevant = {\"aatype\", \"seq_mask\", \"residx_atom37_to_atom14\", \"atom37_atom_exists\"}\n",
    "            batch_of_list.append({k: v for k, v in of_feats.items() if k in relevant})\n",
    "            \n",
    "            # Collect Ground Truth Coords (from mdCATH)\n",
    "            gt_coords_list.append(torch.tensor(item[\"coords\"]))\n",
    "\n",
    "        # --- C. Padding ---\n",
    "        max_len = max(len(s) for s in seq_tokens_list)\n",
    "        \n",
    "        # 1. Pad ESM Tokens (1 is usually padding in ESM alphabet)\n",
    "        padded_seqs = torch.stack([\n",
    "            F.pad(s, (0, max_len - len(s)), value=1) for s in seq_tokens_list\n",
    "        ])\n",
    "        \n",
    "        # 2. Pad Masks\n",
    "        padded_masks = torch.stack([\n",
    "            F.pad(m, (0, max_len - len(m)), value=0) for m in masks_list\n",
    "        ])\n",
    "        \n",
    "        # 3. Pad OpenFold Features\n",
    "        batched_of = {}\n",
    "        if batch_of_list:\n",
    "            for k in batch_of_list[0].keys():\n",
    "                feats = [d[k] for d in batch_of_list]\n",
    "                # Pad the first dimension (sequence length)\n",
    "                batched_of[k] = torch.stack([\n",
    "                    F.pad(f, [0] * 2 * (len(f.shape) - 1) + [0, max_len - f.shape[0]], value=0) \n",
    "                    for f in feats\n",
    "                ])\n",
    "\n",
    "        # 4. Pad Ground Truth Coords\n",
    "        # shape: (Batch, Max_Len, 3)\n",
    "        padded_coords = torch.nn.utils.rnn.pad_sequence(\n",
    "            gt_coords_list, batch_first=True, padding_value=0.0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"id\": ids,\n",
    "            \"seq\": padded_seqs,\n",
    "            \"mask\": padded_masks,\n",
    "            \"batch_of\": batched_of,\n",
    "            \"gt_coords\": padded_coords\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2547669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/mini_latent_pd/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Initializing Streaming Dataset ---\n",
      "--- 2. Running DataLoader with Padding ---\n",
      "Generator finding files... (using subset of 4)\n",
      "\n",
      "Batch 1\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 2\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 3\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 4\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 5\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "Test complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Import the generator from your new file\n",
    "# (Ensure mdcath_dataset.py is in the same folder as your notebook)\n",
    "from mini_latent_pd.data.mdcath_dataset import mdcath_generator\n",
    "\n",
    "# --- Configuration ---\n",
    "REPO_ID = \"compsciencelab/mdCATH\"\n",
    "SUB_SAMPLE_PROTEINS = 4 \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# --- Padding Collator (Keep this in notebook as it's simple) ---\n",
    "def padding_collate(batch):\n",
    "    coords_list = [torch.tensor(item[\"coords\"]) for item in batch]\n",
    "    coords_padded = pad_sequence(coords_list, batch_first=True, padding_value=0.0)\n",
    "    lengths = torch.tensor([len(c) for c in coords_list])\n",
    "    B, Max_L = coords_padded.shape[:2]\n",
    "    mask = torch.arange(Max_L).expand(B, Max_L) < lengths.unsqueeze(1)\n",
    "\n",
    "    return {\n",
    "        \"id\": [item[\"id\"] for item in batch],\n",
    "        \"coords\": coords_padded,\n",
    "        \"mask\": mask,\n",
    "        \"temp\": torch.tensor([item[\"temp\"] for item in batch]),\n",
    "        \"lengths\": lengths\n",
    "    }\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Initializing Streaming Dataset ---\")\n",
    "    \n",
    "    # Now this works because mdcath_generator is an imported function\n",
    "    ds = IterableDataset.from_generator(\n",
    "        mdcath_generator, \n",
    "        gen_kwargs={\"repo_id\": REPO_ID, \"sub_sample_proteins\": SUB_SAMPLE_PROTEINS}\n",
    "    )\n",
    "    \n",
    "    # Optional: Hugging Face dataset mapping\n",
    "    ds = ds.map(lambda x: {\"num_atoms\": len(x[\"coords\"])})\n",
    "\n",
    "    print(\"--- 2. Running DataLoader with Padding ---\")\n",
    "    dataloader = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=padding_collate)\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(f\"\\nBatch {i+1}\")\n",
    "        print(f\"  IDs: {batch['id']}\")\n",
    "        print(f\"  Coords Shape: {batch['coords'].shape} (Padded)\")\n",
    "        \n",
    "        if i >= 4: \n",
    "            print(\"Test complete.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f249c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading minifold_12L.ckpt...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Config\n",
    "cache_dir = Path(\"./minifold_cache\")\n",
    "model_size = \"12L\" # or \"48L\" if you want the larger one\n",
    "filename = f\"minifold_{model_size}.ckpt\"\n",
    "target_path = cache_dir / filename\n",
    "\n",
    "# Create dir\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download if missing\n",
    "if not target_path.exists():\n",
    "    print(f\"Downloading {filename}...\")\n",
    "    url = f\"https://huggingface.co/jwohlwend/minifold/resolve/main/minifold_{model_size}_final.ckpt\"\n",
    "    urllib.request.urlretrieve(url, str(target_path))\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(f\"Found checkpoint at {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a97a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_batch(batch, max_len=600):\n",
    "    \"\"\"\n",
    "    Hard-crops a batch to a maximum length to prevent OOM/Buffer errors.\n",
    "    \"\"\"\n",
    "    current_len = batch[\"seq\"].shape[1]\n",
    "    if current_len <= max_len:\n",
    "        return batch\n",
    "    \n",
    "    print(f\"⚠️ Cropping batch from {current_len} to {max_len} for testing...\")\n",
    "    \n",
    "    # Crop sequence and mask\n",
    "    new_batch = {\n",
    "        \"seq\": batch[\"seq\"][:, :max_len],\n",
    "        \"mask\": batch[\"mask\"][:, :max_len],\n",
    "        \"batch_of\": {},\n",
    "        \"id\": batch[\"id\"] # Keep IDs\n",
    "    }\n",
    "    \n",
    "    # Crop OpenFold features (careful with dimensions)\n",
    "    for k, v in batch[\"batch_of\"].items():\n",
    "        if v.shape[1] == current_len:\n",
    "             # Assuming dim 1 is sequence length (Batch, Len, ...)\n",
    "            new_batch[\"batch_of\"][k] = v[:, :max_len, ...]\n",
    "        else:\n",
    "            # Some features might not map directly to len (check specific keys if needed)\n",
    "            new_batch[\"batch_of\"][k] = v\n",
    "            \n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb53c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading checkpoint from minifold_cache/minifold_12L.ckpt...\n",
      "Fetching batch...\n",
      "Generator finding files... (using subset of 4)\n",
      "Running inference for protein IDs: ['1l1cA00', '1l1cA00']\n",
      "\n",
      "Success!\n",
      "Latent Pair Representation shape: torch.Size([2, 883, 883, 128])\n",
      "Predicted Coordinates shape: torch.Size([2, 883, 37, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/mini_latent_pd/src/mini_latent_pd/models/minifold/utils/tensor_utils.py:86: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)\n",
      "  return data[ranges]\n"
     ]
    }
   ],
   "source": [
    "from mini_latent_pd.data.mdcath_dataset import mdcath_generator\n",
    "\n",
    "# 1. Setup Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Load Model\n",
    "# Ensure you point cache_dir to where predict.py downloaded weights\n",
    "model, alphabet, config = load_minifold_model(cache_dir=\"./minifold_cache\", model_size=\"12L\", device=device)\n",
    "\n",
    "# 3. Prepare Dataset\n",
    "# (Assuming mdcath_generator is defined in a previous cell)\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import IterableDataset\n",
    "\n",
    "ds = IterableDataset.from_generator(\n",
    "        mdcath_generator, \n",
    "        gen_kwargs={\"repo_id\": REPO_ID, \"sub_sample_proteins\": SUB_SAMPLE_PROTEINS}\n",
    "    )\n",
    "collator = MinifoldCollator(alphabet, config)\n",
    "\n",
    "# 4. Create DataLoader\n",
    "loader = DataLoader(ds, batch_size=2, collate_fn=collator)\n",
    "\n",
    "# 5. Run a Test Batch\n",
    "print(\"Fetching batch...\")\n",
    "batch = next(iter(loader))\n",
    "\n",
    "# Move to device\n",
    "batch_gpu = {\n",
    "    \"seq\": batch[\"seq\"].to(device),\n",
    "    \"mask\": batch[\"mask\"].to(device),\n",
    "    \"batch_of\": {k: v.to(device) for k, v in batch[\"batch_of\"].items()}\n",
    "}\n",
    "\n",
    "# batch_gpu = crop_batch(batch_gpu, max_len=512)\n",
    "\n",
    "print(f\"Running inference for protein IDs: {batch['id']}\")\n",
    "with torch.no_grad():\n",
    "    # Run MiniFold!\n",
    "    output = model(batch_gpu)\n",
    "\n",
    "print(\"\\nSuccess!\")\n",
    "print(\"Latent Pair Representation shape:\", output[\"pair\"].shape) # (B, L, L, 128)\n",
    "print(\"Predicted Coordinates shape:\", output[\"final_atom_positions\"].shape) # (B, L, 37, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3fa17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: torch.Size([2, 883, 883, 64])\n",
      "pair: torch.Size([2, 883, 883, 128])\n",
      "single: torch.Size([2, 883, 1024])\n",
      "sm: <class 'dict'>\n",
      "final_atom_positions: torch.Size([2, 883, 37, 3])\n",
      "final_atom_mask: torch.Size([2, 883, 37])\n",
      "final_affine_tensor: torch.Size([2, 883, 4, 4])\n",
      "lddt_logits: torch.Size([2, 883, 50])\n",
      "plddt: torch.Size([2, 883])\n"
     ]
    }
   ],
   "source": [
    "for key, value in output.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, torch.Tensor) else type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d477cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: <class 'list'>\n",
      "seq: torch.Size([2, 883])\n",
      "mask: torch.Size([2, 883])\n",
      "batch_of: <class 'dict'>\n",
      "gt_coords: torch.Size([2, 883, 3])\n"
     ]
    }
   ],
   "source": [
    "for key, value in batch.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, torch.Tensor) else type(value)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_latent_pd (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
