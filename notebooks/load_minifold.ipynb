{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eaad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_latent_pd.models.minifold.model.model import MiniFoldModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66ef075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4b97539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from mini_latent_pd.models.minifold.model.model import MiniFoldModel\n",
    "from mini_latent_pd.models.minifold.data.config import model_config\n",
    "from mini_latent_pd.models.minifold.data.of_data import of_inference\n",
    "from mini_latent_pd.models.minifold.utils.residue_constants import restype_order_with_x_inverse\n",
    "from esm.pretrained import load_model_and_alphabet\n",
    "\n",
    "def load_minifold_model(cache_dir=\"./minifold_cache\", model_size=\"48L\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Loads the MiniFold model, alphabet, and config for interactive use.\n",
    "    \"\"\"\n",
    "    # 1. Paths\n",
    "    cache = Path(cache_dir).expanduser()\n",
    "    checkpoint_path = cache / f\"minifold_{model_size}.ckpt\"\n",
    "    \n",
    "    if not checkpoint_path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}. Run predict.py once to download it.\")\n",
    "\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "    \n",
    "    # 2. Load Checkpoint & Hyperparams\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    hparams = ckpt[\"hyper_parameters\"]\n",
    "    \n",
    "    # 3. Initialize Model\n",
    "    # We create the config required for feature generation\n",
    "    config_of = model_config(\n",
    "        \"initial_training\",\n",
    "        train=False,\n",
    "        low_prec=False,\n",
    "        long_sequence_inference=False,\n",
    "    )\n",
    "    \n",
    "    model = MiniFoldModel(\n",
    "        esm_model_name=hparams[\"esm_model_name\"],\n",
    "        num_blocks=hparams[\"num_blocks\"],\n",
    "        no_bins=hparams[\"no_bins\"],\n",
    "        config_of=config_of,\n",
    "        use_structure_module=True,\n",
    "        kernels=False, # Important: False for Mac/MPS compatibility\n",
    "    )\n",
    "\n",
    "    # 4. Load State Dict\n",
    "    state_dict = ckpt[\"state_dict\"]\n",
    "    # Clean keys as done in predict.py\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"boundaries\" not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"mid_points\" not in k}\n",
    "    state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "    state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 5. Load Alphabet (needed for tokenizing sequences)\n",
    "    _, alphabet = load_model_and_alphabet(hparams[\"esm_model_name\"])\n",
    "    \n",
    "    return model, alphabet, config_of.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9199a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinifoldCollator:\n",
    "    def __init__(self, alphabet, config):\n",
    "        self.alphabet = alphabet\n",
    "        self.config = config\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        \"\"\"\n",
    "        Transforms a list of mdCATH dicts into a MiniFold batch.\n",
    "        \"\"\"\n",
    "        seq_tokens_list = []\n",
    "        masks_list = []\n",
    "        batch_of_list = []\n",
    "        gt_coords_list = []\n",
    "        ids = []\n",
    "\n",
    "        for item in batch:\n",
    "            seq_str = item[\"sequence\"]\n",
    "            ids.append(item[\"id\"])\n",
    "            \n",
    "            # --- A. Generate Features ---\n",
    "            # This replicates predict.py's `prepare_input`\n",
    "            of_feats = of_inference(seq_str, \"predict\", self.config)\n",
    "            \n",
    "            # Reconstruct clean sequence from features to ensure alignment\n",
    "            clean_seq = \"\".join(\n",
    "                [restype_order_with_x_inverse[x.item()] for x in of_feats[\"aatype\"]]\n",
    "            )[: of_feats[\"seq_length\"]]\n",
    "            \n",
    "            # Encode for ESM\n",
    "            encoded_seq = torch.tensor(self.alphabet.encode(clean_seq), dtype=torch.long)\n",
    "            \n",
    "            # --- B. Collect ---\n",
    "            seq_tokens_list.append(encoded_seq)\n",
    "            masks_list.append(of_feats[\"seq_mask\"][:, 0].bool())\n",
    "            \n",
    "            # Filter OpenFold features to only what MiniFold needs\n",
    "            relevant = {\"aatype\", \"seq_mask\", \"residx_atom37_to_atom14\", \"atom37_atom_exists\"}\n",
    "            batch_of_list.append({k: v for k, v in of_feats.items() if k in relevant})\n",
    "            \n",
    "            # Collect Ground Truth Coords (from mdCATH)\n",
    "            gt_coords_list.append(torch.tensor(item[\"coords\"]))\n",
    "\n",
    "        # --- C. Padding ---\n",
    "        max_len = max(len(s) for s in seq_tokens_list)\n",
    "        \n",
    "        # 1. Pad ESM Tokens (1 is usually padding in ESM alphabet)\n",
    "        padded_seqs = torch.stack([\n",
    "            F.pad(s, (0, max_len - len(s)), value=1) for s in seq_tokens_list\n",
    "        ])\n",
    "        \n",
    "        # 2. Pad Masks\n",
    "        padded_masks = torch.stack([\n",
    "            F.pad(m, (0, max_len - len(m)), value=0) for m in masks_list\n",
    "        ])\n",
    "        \n",
    "        # 3. Pad OpenFold Features\n",
    "        batched_of = {}\n",
    "        if batch_of_list:\n",
    "            for k in batch_of_list[0].keys():\n",
    "                feats = [d[k] for d in batch_of_list]\n",
    "                # Pad the first dimension (sequence length)\n",
    "                batched_of[k] = torch.stack([\n",
    "                    F.pad(f, [0] * 2 * (len(f.shape) - 1) + [0, max_len - f.shape[0]], value=0) \n",
    "                    for f in feats\n",
    "                ])\n",
    "\n",
    "        # 4. Pad Ground Truth Coords\n",
    "        # shape: (Batch, Max_Len, 3)\n",
    "        padded_coords = torch.nn.utils.rnn.pad_sequence(\n",
    "            gt_coords_list, batch_first=True, padding_value=0.0\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"id\": ids,\n",
    "            \"seq\": padded_seqs,\n",
    "            \"mask\": padded_masks,\n",
    "            \"batch_of\": batched_of,\n",
    "            \"gt_coords\": padded_coords\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2547669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/mini_latent_pd/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Initializing Streaming Dataset ---\n",
      "--- 2. Running DataLoader with Padding ---\n",
      "Generator finding files... (using subset of 4)\n",
      "\n",
      "Batch 1\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 2\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 3\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 4\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "\n",
      "Batch 5\n",
      "  IDs: ['2cw7A03']\n",
      "  Coords Shape: torch.Size([1, 2769, 3]) (Padded)\n",
      "Test complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Import the generator from your new file\n",
    "# (Ensure mdcath_dataset.py is in the same folder as your notebook)\n",
    "from mini_latent_pd.data.mdcath_dataset import mdcath_generator\n",
    "\n",
    "# --- Configuration ---\n",
    "REPO_ID = \"compsciencelab/mdCATH\"\n",
    "SUB_SAMPLE_PROTEINS = 4 \n",
    "BATCH_SIZE = 1\n",
    "\n",
    "# --- Padding Collator (Keep this in notebook as it's simple) ---\n",
    "def padding_collate(batch):\n",
    "    coords_list = [torch.tensor(item[\"coords\"]) for item in batch]\n",
    "    coords_padded = pad_sequence(coords_list, batch_first=True, padding_value=0.0)\n",
    "    lengths = torch.tensor([len(c) for c in coords_list])\n",
    "    B, Max_L = coords_padded.shape[:2]\n",
    "    mask = torch.arange(Max_L).expand(B, Max_L) < lengths.unsqueeze(1)\n",
    "\n",
    "    return {\n",
    "        \"id\": [item[\"id\"] for item in batch],\n",
    "        \"coords\": coords_padded,\n",
    "        \"mask\": mask,\n",
    "        \"temp\": torch.tensor([item[\"temp\"] for item in batch]),\n",
    "        \"lengths\": lengths\n",
    "    }\n",
    "\n",
    "# --- Execution ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- 1. Initializing Streaming Dataset ---\")\n",
    "    \n",
    "    # Now this works because mdcath_generator is an imported function\n",
    "    ds = IterableDataset.from_generator(\n",
    "        mdcath_generator, \n",
    "        gen_kwargs={\"repo_id\": REPO_ID, \"sub_sample_proteins\": SUB_SAMPLE_PROTEINS}\n",
    "    )\n",
    "    \n",
    "    # Optional: Hugging Face dataset mapping\n",
    "    ds = ds.map(lambda x: {\"num_atoms\": len(x[\"coords\"])})\n",
    "\n",
    "    print(\"--- 2. Running DataLoader with Padding ---\")\n",
    "    dataloader = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=padding_collate)\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        print(f\"\\nBatch {i+1}\")\n",
    "        print(f\"  IDs: {batch['id']}\")\n",
    "        print(f\"  Coords Shape: {batch['coords'].shape} (Padded)\")\n",
    "        \n",
    "        if i >= 4: \n",
    "            print(\"Test complete.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f249c160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading minifold_12L.ckpt...\n",
      "Download complete.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "# Config\n",
    "cache_dir = Path(\"./minifold_cache\")\n",
    "model_size = \"12L\" # or \"48L\" if you want the larger one\n",
    "filename = f\"minifold_{model_size}.ckpt\"\n",
    "target_path = cache_dir / filename\n",
    "\n",
    "# Create dir\n",
    "cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download if missing\n",
    "if not target_path.exists():\n",
    "    print(f\"Downloading {filename}...\")\n",
    "    url = f\"https://huggingface.co/jwohlwend/minifold/resolve/main/minifold_{model_size}_final.ckpt\"\n",
    "    urllib.request.urlretrieve(url, str(target_path))\n",
    "    print(\"Download complete.\")\n",
    "else:\n",
    "    print(f\"Found checkpoint at {target_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5a97a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_batch(batch, max_len=600):\n",
    "    \"\"\"\n",
    "    Hard-crops a batch to a maximum length to prevent OOM/Buffer errors.\n",
    "    \"\"\"\n",
    "    current_len = batch[\"seq\"].shape[1]\n",
    "    if current_len <= max_len:\n",
    "        return batch\n",
    "    \n",
    "    print(f\"⚠️ Cropping batch from {current_len} to {max_len} for testing...\")\n",
    "    \n",
    "    # Crop sequence and mask\n",
    "    new_batch = {\n",
    "        \"seq\": batch[\"seq\"][:, :max_len],\n",
    "        \"mask\": batch[\"mask\"][:, :max_len],\n",
    "        \"batch_of\": {},\n",
    "        \"id\": batch[\"id\"] # Keep IDs\n",
    "    }\n",
    "    \n",
    "    # Crop OpenFold features (careful with dimensions)\n",
    "    for k, v in batch[\"batch_of\"].items():\n",
    "        if v.shape[1] == current_len:\n",
    "             # Assuming dim 1 is sequence length (Batch, Len, ...)\n",
    "            new_batch[\"batch_of\"][k] = v[:, :max_len, ...]\n",
    "        else:\n",
    "            # Some features might not map directly to len (check specific keys if needed)\n",
    "            new_batch[\"batch_of\"][k] = v\n",
    "            \n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb53c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Loading checkpoint from minifold_cache/minifold_12L.ckpt...\n",
      "Fetching batch...\n",
      "Generator finding files... (using subset of 4)\n",
      "Running inference for protein IDs: ['1l1cA00', '1l1cA00']\n",
      "\n",
      "Success!\n",
      "Latent Pair Representation shape: torch.Size([2, 883, 883, 128])\n",
      "Predicted Coordinates shape: torch.Size([2, 883, 37, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/moustholmes/mini_latent_pd/src/mini_latent_pd/models/minifold/utils/tensor_utils.py:86: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_variable_indexing.cpp:312.)\n",
      "  return data[ranges]\n"
     ]
    }
   ],
   "source": [
    "from mini_latent_pd.data.mdcath_dataset import mdcath_generator\n",
    "\n",
    "# 1. Setup Device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Load Model\n",
    "# Ensure you point cache_dir to where predict.py downloaded weights\n",
    "model, alphabet, config = load_minifold_model(cache_dir=\"./minifold_cache\", model_size=\"12L\", device=device)\n",
    "\n",
    "# 3. Prepare Dataset\n",
    "# (Assuming mdcath_generator is defined in a previous cell)\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import IterableDataset\n",
    "\n",
    "ds = IterableDataset.from_generator(\n",
    "        mdcath_generator, \n",
    "        gen_kwargs={\"repo_id\": REPO_ID, \"sub_sample_proteins\": SUB_SAMPLE_PROTEINS}\n",
    "    )\n",
    "collator = MinifoldCollator(alphabet, config)\n",
    "\n",
    "# 4. Create DataLoader\n",
    "loader = DataLoader(ds, batch_size=2, collate_fn=collator)\n",
    "\n",
    "# 5. Run a Test Batch\n",
    "print(\"Fetching batch...\")\n",
    "batch = next(iter(loader))\n",
    "\n",
    "# Move to device\n",
    "batch_gpu = {\n",
    "    \"seq\": batch[\"seq\"].to(device),\n",
    "    \"mask\": batch[\"mask\"].to(device),\n",
    "    \"batch_of\": {k: v.to(device) for k, v in batch[\"batch_of\"].items()}\n",
    "}\n",
    "\n",
    "# batch_gpu = crop_batch(batch_gpu, max_len=512)\n",
    "\n",
    "print(f\"Running inference for protein IDs: {batch['id']}\")\n",
    "with torch.no_grad():\n",
    "    # Run MiniFold!\n",
    "    output = model(batch_gpu)\n",
    "\n",
    "print(\"\\nSuccess!\")\n",
    "print(\"Latent Pair Representation shape:\", output[\"pair\"].shape) # (B, L, L, 128)\n",
    "print(\"Predicted Coordinates shape:\", output[\"final_atom_positions\"].shape) # (B, L, 37, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d477cc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: <class 'list'>\n",
      "seq: torch.Size([2, 883])\n",
      "mask: torch.Size([2, 883])\n",
      "batch_of: <class 'dict'>\n",
      "gt_coords: torch.Size([2, 883, 3])\n"
     ]
    }
   ],
   "source": [
    "for key, value in batch.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, torch.Tensor) else type(value)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f086a6",
   "metadata": {},
   "source": [
    "1. The Input Batch\n",
    "\n",
    "These are the tensors fed into the model.\n",
    "\n",
    "- id: ['1ABC', '2XYZ']\n",
    "\n",
    "A list of the protein identifiers for tracking which file corresponds to which output.\n",
    "- seq: (2, 883)\n",
    "\n",
    "What it is: The ESM token indices for the amino acid sequence.\n",
    "\n",
    "Details: Integers representing amino acids. The padding value (usually 1) is used for any protein shorter than 883 residues.\n",
    "- mask: (2, 883)\n",
    "\n",
    "What it is: A boolean mask indicating where real data exists versus padding.\n",
    "\n",
    "        Values: 1 (True) for real residues, 0 (False) for padded regions. You must use this to mask your loss function during training, or the model will try to fold the padding zeros.\n",
    "\n",
    "- batch_of: <dict>\n",
    "\n",
    "        What it is: Pre-computed geometric features needed by the structure module (e.g., rigid body frame definitions for each amino acid type).\n",
    "\n",
    "        Key contents: aatype (amino acid identity), rigid_group_default_frame (local frames for side chains).\n",
    "\n",
    "- gt_coords: (2, 883, 3)\n",
    "\n",
    "        What it is: Your Ground Truth coordinates from mdCATH.\n",
    "\n",
    "        Note: Since the last dimension is 3, this contains only one atom per residue (likely Alpha Carbon, CA). You will use this to calculate the loss against the model's predicted CA atoms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81f615",
   "metadata": {},
   "source": [
    "2. The Model Output\n",
    "\n",
    "These are the tensors returned by model(batch).\n",
    "A. The Latent Spaces \n",
    "\n",
    "    pair: (2, 883, 883, 128)\n",
    "\n",
    "        What it is: The Geometry-Aware Latent Space (sz​).\n",
    "\n",
    "        Significance: This is the output of the \"Folding Trunk\" (the MiniFormer). It represents the relationship between every pair of residues (L×L).\n",
    "\n",
    "        For your project: This is the tensor you should encode/diffuse/modify. It contains the rich evolutionary and structural constraints before they are realized into 3D coordinates.\n",
    "\n",
    "    single: (2, 883, 1024)\n",
    "\n",
    "        What it is: The Single Latent Representation (ss​).\n",
    "\n",
    "        Significance: A projection of the ESM embeddings mixed with structural info. It serves as the primary input to the Structure Module to generate the backbone frames.\n",
    "\n",
    "B. The Structural Outputs (The Decoder)\n",
    "\n",
    "These are generated by the StructureModule from the latent spaces.\n",
    "\n",
    "    final_atom_positions: (2, 883, 37, 3)\n",
    "\n",
    "        What it is: The predicted 3D coordinates for all heavy atoms.\n",
    "\n",
    "        Dimensions:\n",
    "\n",
    "            37: The standard mapping for up to 37 heavy atoms (N, CA, C, O, CB, ...).\n",
    "\n",
    "            3: X, Y, Z coordinates (in Angstroms).\n",
    "\n",
    "        Note: To calculate loss against your gt_coords (CA only), you need to extract the CA atom (index 1) from this tensor: pred_ca = output['final_atom_positions'][:, :, 1, :].\n",
    "\n",
    "    final_atom_mask: (2, 883, 37)\n",
    "\n",
    "        What it is: Tells you which of the 37 atoms actually exist for a given amino acid (e.g., Glycine has no Beta Carbon, so its index would be 0 here).\n",
    "\n",
    "    final_affine_tensor: (2, 883, 4, 4)\n",
    "\n",
    "        What it is: The predicted rotation and translation matrices (frames) for every residue's backbone. The Structure Module predicts these frames first, then places the atoms into them.\n",
    "\n",
    "C. Probabilistic Outputs & Confidence\n",
    "\n",
    "    preds: (2, 883, 883, 64)\n",
    "\n",
    "        What it is: The Distogram Logits.\n",
    "\n",
    "        Details: It predicts the probability of the distance between two residues falling into one of 64 bins (e.g., bin 0 = 2-4 Angstroms, bin 63 = >22 Angstroms).\n",
    "\n",
    "    plddt: (2, 883)\n",
    "\n",
    "        What it is: The per-residue confidence score (0-100). High values mean the model is confident in that region's structure.\n",
    "\n",
    "    lddt_logits: (2, 883, 50)\n",
    "\n",
    "        What it is: The raw logits used to calculate the plddt score.\n",
    "\n",
    "    sm: <dict>\n",
    "\n",
    "        What it is: Internal debug state of the Structure Module (e.g., side-chain torsion angles). You can usually ignore this unless you are debugging specific side-chain rotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f3fa17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds: torch.Size([2, 883, 883, 64])\n",
      "pair: torch.Size([2, 883, 883, 128])\n",
      "single: torch.Size([2, 883, 1024])\n",
      "sm: <class 'dict'>\n",
      "final_atom_positions: torch.Size([2, 883, 37, 3])\n",
      "final_atom_mask: torch.Size([2, 883, 37])\n",
      "final_affine_tensor: torch.Size([2, 883, 4, 4])\n",
      "lddt_logits: torch.Size([2, 883, 50])\n",
      "plddt: torch.Size([2, 883])\n"
     ]
    }
   ],
   "source": [
    "for key, value in output.items():\n",
    "    print(f\"{key}: {value.shape if isinstance(value, torch.Tensor) else type(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1525085c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aatype': tensor([[[12],\n",
       "          [12],\n",
       "          [12],\n",
       "          ...,\n",
       "          [19],\n",
       "          [19],\n",
       "          [19]],\n",
       " \n",
       "         [[12],\n",
       "          [12],\n",
       "          [12],\n",
       "          ...,\n",
       "          [19],\n",
       "          [19],\n",
       "          [19]]]),\n",
       " 'seq_mask': tensor([[[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]],\n",
       " \n",
       "         [[1.],\n",
       "          [1.],\n",
       "          [1.],\n",
       "          ...,\n",
       "          [1.],\n",
       "          [1.],\n",
       "          [1.]]]),\n",
       " 'residx_atom37_to_atom14': tensor([[[[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]]],\n",
       " \n",
       " \n",
       "         [[[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]],\n",
       " \n",
       "          [[0],\n",
       "           [1],\n",
       "           [2],\n",
       "           ...,\n",
       "           [0],\n",
       "           [0],\n",
       "           [0]]]]),\n",
       " 'atom37_atom_exists': tensor([[[[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]],\n",
       " \n",
       " \n",
       "         [[[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]],\n",
       " \n",
       "          [[1.],\n",
       "           [1.],\n",
       "           [1.],\n",
       "           ...,\n",
       "           [0.],\n",
       "           [0.],\n",
       "           [0.]]]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['batch_of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58a04d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-96.3977,   5.6547,  -6.8404],\n",
       "         [-95.3969,   4.2691,  -7.1769],\n",
       "         [-94.0278,   5.1603,  -7.7622],\n",
       "         ...,\n",
       "         [ 32.4375,   2.9705,   4.2263],\n",
       "         [ 32.9936,  -0.4333,   3.6020],\n",
       "         [ 33.3603,   0.5361,   0.8055]],\n",
       "\n",
       "        [[-22.7918,   4.1711,   1.4760],\n",
       "         [-23.7921,   2.8411,   3.4759],\n",
       "         [-22.2749,   1.5842,   1.8703],\n",
       "         ...,\n",
       "         [  0.2235,  -0.8644,   0.6441],\n",
       "         [  0.7852,  -1.4505,   1.4023],\n",
       "         [  1.0849,  -1.3420,  -0.4275]]], device='mps:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['final_atom_positions'][:, :, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a236231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 69.3777,  47.4753,  42.9504],\n",
       "         [ 68.8169,  48.2709,  42.4469],\n",
       "         [ 66.2578,  48.5597,  43.3122],\n",
       "         ...,\n",
       "         [-87.0375,  58.2095,  30.0537],\n",
       "         [-86.8236,  60.1133,  31.2680],\n",
       "         [-86.4503,  60.6439,  34.6745]],\n",
       "\n",
       "        [[ -4.5482,  57.4589,  48.6540],\n",
       "         [ -3.9879,  58.8489,  45.6341],\n",
       "         [ -4.5651,  61.0158,  48.4797],\n",
       "         ...,\n",
       "         [-21.0835,  45.5444,  63.6059],\n",
       "         [-20.2252,  45.0405,  63.1377],\n",
       "         [-22.1349,  44.2520,  64.9275]]], device='mps:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['gt_coords'].to(device)-output['final_atom_positions'][:, :, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff499dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from mini_latent_pd.models.minifold.model.model import MiniFoldModel\n",
    "from mini_latent_pd.models.minifold.data.config import model_config\n",
    "from mini_latent_pd.models.minifold.data.of_data import of_inference\n",
    "from mini_latent_pd.models.minifold.utils.residue_constants import restype_order_with_x_inverse\n",
    "from esm.pretrained import load_model_and_alphabet\n",
    "\n",
    "def load_minifold_model(cache_dir=\"./minifold_cache\", model_size=\"48L\", device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Loads the MiniFold model, alphabet, and config for interactive use.\n",
    "    \"\"\"\n",
    "    # 1. Paths\n",
    "    cache = Path(cache_dir).expanduser()\n",
    "    checkpoint_path = cache / f\"minifold_{model_size}.ckpt\"\n",
    "    \n",
    "    if not checkpoint_path.exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found at {checkpoint_path}. Run predict.py once to download it.\")\n",
    "\n",
    "    print(f\"Loading checkpoint from {checkpoint_path}...\")\n",
    "    \n",
    "    # 2. Load Checkpoint & Hyperparams\n",
    "    ckpt = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    hparams = ckpt[\"hyper_parameters\"]\n",
    "    \n",
    "    # 3. Initialize Model\n",
    "    # We create the config required for feature generation\n",
    "    config_of = model_config(\n",
    "        \"initial_training\",\n",
    "        train=False,\n",
    "        low_prec=False,\n",
    "        long_sequence_inference=False,\n",
    "    )\n",
    "    \n",
    "    model = MiniFoldModel(\n",
    "        esm_model_name=hparams[\"esm_model_name\"],\n",
    "        num_blocks=hparams[\"num_blocks\"],\n",
    "        no_bins=hparams[\"no_bins\"],\n",
    "        config_of=config_of,\n",
    "        use_structure_module=True,\n",
    "        kernels=False, # Important: False for Mac/MPS compatibility\n",
    "    )\n",
    "\n",
    "    # 4. Load State Dict\n",
    "    state_dict = ckpt[\"state_dict\"]\n",
    "    # Clean keys as done in predict.py\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"boundaries\" not in k}\n",
    "    state_dict = {k: v for k, v in state_dict.items() if \"mid_points\" not in k}\n",
    "    state_dict = {k.replace(\"_orig_mod.\", \"\"): v for k, v in state_dict.items()}\n",
    "    state_dict = {k.replace(\"model.\", \"\"): v for k, v in state_dict.items()}\n",
    "    \n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # 5. Load Alphabet (needed for tokenizing sequences)\n",
    "    _, alphabet = load_model_and_alphabet(hparams[\"esm_model_name\"])\n",
    "    \n",
    "    return model, alphabet, config_of.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b753d5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini_latent_pd (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
